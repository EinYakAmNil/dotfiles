#!/bin/bash
url=$1
chapter=$(echo $url | rev | cut -d "/" -f 1 | rev)
path=/tmp/$chapter

# Don't download if the PDF file already exists.
if [ -f $path/$chapter.pdf ]; then
	zathura $path/$chapter.pdf &
	disown
	exit 0
fi

mkdir -p $path && cd $path || exit 1

curl --no-progress-meter $url >$path/.html
image_count=$(sed -n 's/<div class="text-sm">page 1\/\([0-9][0-9]*\)<\/div>$/\1/p' $path/.html)

user_agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KH TML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
IMAGE_URL=$(grep "/1.jpeg\"" $path/.html | cut -f 4 -d '"' | sed "s|/1\.jpeg$||")
for i in $(seq $image_count); do
	# index the images from right to left.
	if [[ $(($i % 2)) -eq 0 ]]; then
		j=$((i + 1))
	else
		j=$((i - 1))
	fi
	echo Downloading "$IMAGE_URL/$i.jpeg"
	curl -s --referer "mangapill.com" --user-agent "$user_agent" "$IMAGE_URL/$i.jpeg" >$path/$j.jpg
done

# equal width for leading zeros. Can't do it with seq due to reindexing.
perl-rename "s/^(\d\.)/0\1/" *
magick *.jpg $chapter.pdf
zathura $chapter.pdf &
